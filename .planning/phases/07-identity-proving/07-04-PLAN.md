---
phase: 07-identity-proving
plan: "07-04"
title: "Identity Database (TOML) and Python API Bindings"
wave: 4
depends_on: ["07-01", "07-03"]
requirements: ["IDPR-07", "IDPR-08"]
files_modified:
  - crates/qsym-core/Cargo.toml
  - crates/qsym-core/src/qseries/identity/mod.rs
  - crates/qsym-core/src/qseries/mod.rs
  - crates/qsym-python/src/dsl.rs
  - crates/qsym-python/src/lib.rs
files_created:
  - crates/qsym-core/src/qseries/identity/database.rs
  - data/identities/classical_identities.toml
  - crates/qsym-core/tests/qseries_identity_database_tests.rs
estimated_tasks: 3

must_haves:
  truths:
    - "Identity database TOML files can be loaded, parsed, and searched by tag, function type, and structural pattern"
    - "At least 10 well-known identities are seeded in the database with citations"
    - "Python API can call prove_eta_identity and inspect ProofResult"
    - "Python API can search the identity database by tags"
    - "TOML schema supports eta_quotient identity type with factors, level, and citation"
  artifacts:
    - path: "crates/qsym-core/src/qseries/identity/database.rs"
      provides: "IdentityEntry, IdentityDatabase, TOML load/save/search"
      exports: ["IdentityEntry", "IdentityDatabase"]
    - path: "data/identities/classical_identities.toml"
      provides: "Seeded collection of at least 10 classical identities"
      min_lines: 80
    - path: "crates/qsym-python/src/dsl.rs"
      provides: "Python bindings for identity proving and database search"
      contains: "prove_eta_identity"
    - path: "crates/qsym-core/tests/qseries_identity_database_tests.rs"
      provides: "Tests for TOML loading, searching, and round-trip serialization"
      min_lines: 100
  key_links:
    - from: "crates/qsym-core/src/qseries/identity/database.rs"
      to: "data/identities/classical_identities.toml"
      via: "TOML deserialization with serde"
      pattern: "toml::from_str"
    - from: "crates/qsym-python/src/dsl.rs"
      to: "crates/qsym-core/src/qseries/identity/prove.rs"
      via: "prove_eta_identity function call"
      pattern: "prove_eta_identity"
    - from: "crates/qsym-python/src/dsl.rs"
      to: "crates/qsym-core/src/qseries/identity/database.rs"
      via: "IdentityDatabase for search"
      pattern: "IdentityDatabase"
---

<objective>
Create the identity database infrastructure (TOML-based, searchable) and Python API bindings for identity proving and database lookup. This completes the user-facing API for Phase 7.

Purpose: IDPR-07 and IDPR-08 require a searchable collection of verified identities and the ability to look them up by tags, functions, and patterns. Python bindings make the proving engine accessible from the research workflow.

Output: database.rs with TOML load/save/search, seeded identity file, Python bindings in dsl.rs, integration tests.
</objective>

<execution_context>
@C:/Users/Owner/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Owner/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-identity-proving/07-RESEARCH.md

@crates/qsym-core/Cargo.toml
@crates/qsym-core/src/qseries/identity/mod.rs
@crates/qsym-core/src/qseries/identity/eta.rs
@crates/qsym-core/src/qseries/identity/prove.rs
@crates/qsym-core/src/qseries/mod.rs
@crates/qsym-python/src/dsl.rs
@crates/qsym-python/src/lib.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add toml dependency, create database.rs with TOML schema and search</name>
  <files>
    crates/qsym-core/Cargo.toml
    crates/qsym-core/src/qseries/identity/database.rs
    crates/qsym-core/src/qseries/identity/mod.rs
    crates/qsym-core/src/qseries/mod.rs
  </files>
  <action>
**Step 1: Add `toml` dependency to qsym-core/Cargo.toml.**

Add under `[dependencies]`:
```toml
toml = "0.8"
```

The `serde` crate with `derive` feature is already present, so TOML deserialization will work out of the box with `#[derive(Serialize, Deserialize)]`.

**Step 2: Create database.rs with identity types and search.**

```rust
//! Identity database: TOML-based searchable collection of verified q-series identities.
//!
//! Provides:
//! - [`IdentityEntry`]: a single identity with metadata, terms, and citation
//! - [`IdentityDatabase`]: collection of identities with search by tag, function, pattern
//! - TOML serialization/deserialization via serde
```

**IdentitySide struct** -- `#[derive(Clone, Debug, Serialize, Deserialize)]`:
```rust
/// One side of an identity (LHS or RHS), in eta-quotient form.
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct IdentitySide {
    /// The type of expression ("eta_quotient", "q_series", "theta", "jac")
    #[serde(rename = "type")]
    pub expr_type: String,
    /// Level N for eta quotients (optional for other types)
    pub level: Option<i64>,
    /// Eta quotient factors: maps delta -> r_delta
    /// Serialized as { "1" = 2, "5" = -3 } in TOML
    pub factors: Option<BTreeMap<String, i64>>,
    /// Free-form formula description (for display / non-eta types)
    pub formula: Option<String>,
}
```

**CitationInfo struct** -- `#[derive(Clone, Debug, Serialize, Deserialize)]`:
```rust
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CitationInfo {
    pub author: Option<String>,
    pub year: Option<i64>,
    pub reference: Option<String>,
    pub doi: Option<String>,
}
```

**ProofInfo struct** -- `#[derive(Clone, Debug, Serialize, Deserialize)]`:
```rust
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ProofInfo {
    pub method: Option<String>,   // "valence_formula", "q_expansion", "bijective"
    pub level: Option<i64>,
    pub verified: Option<bool>,
}
```

**IdentityEntry struct** -- `#[derive(Clone, Debug, Serialize, Deserialize)]`:
```rust
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct IdentityEntry {
    /// Unique identifier (e.g., "euler-pentagonal", "jacobi-triple-product")
    pub id: String,
    /// Human-readable name
    pub name: String,
    /// Tags for categorization and search
    pub tags: Vec<String>,
    /// Functions involved (e.g., ["eta"], ["eta", "theta"], ["jac"])
    pub functions: Vec<String>,
    /// Left-hand side of the identity
    pub lhs: IdentitySide,
    /// Right-hand side of the identity
    pub rhs: IdentitySide,
    /// Proof information
    pub proof: Option<ProofInfo>,
    /// Citation information
    pub citation: Option<CitationInfo>,
}
```

**IdentityFile struct** (wrapper for TOML top-level):
```rust
#[derive(Clone, Debug, Serialize, Deserialize)]
struct IdentityFile {
    identity: Vec<IdentityEntry>,
}
```

**IdentityDatabase struct** -- public, not serialized:
```rust
/// Searchable collection of verified identities.
pub struct IdentityDatabase {
    entries: Vec<IdentityEntry>,
}
```

Methods:

- `pub fn new() -> Self` -- empty database
- `pub fn load_from_toml(toml_str: &str) -> Result<Self, String>`:
  Parse TOML string into IdentityFile, extract entries.
  ```rust
  let file: IdentityFile = toml::from_str(toml_str)
      .map_err(|e| format!("TOML parse error: {}", e))?;
  Ok(Self { entries: file.identity })
  ```

- `pub fn load_from_file(path: &std::path::Path) -> Result<Self, String>`:
  Read file to string, then call load_from_toml.

- `pub fn add(&mut self, entry: IdentityEntry)`:
  Add a new entry.

- `pub fn len(&self) -> usize`
- `pub fn is_empty(&self) -> bool`
- `pub fn entries(&self) -> &[IdentityEntry]`
- `pub fn get(&self, id: &str) -> Option<&IdentityEntry>`:
  Find by id.

- `pub fn search_by_tag(&self, tag: &str) -> Vec<&IdentityEntry>`:
  Return all entries that contain the given tag (case-insensitive match).

- `pub fn search_by_function(&self, function: &str) -> Vec<&IdentityEntry>`:
  Return all entries whose `functions` list contains the given function name (case-insensitive).

- `pub fn search_by_pattern(&self, pattern: &str) -> Vec<&IdentityEntry>`:
  Search by pattern matching against id, name, tags, functions, and formula fields. Case-insensitive substring match.

- `pub fn to_toml(&self) -> Result<String, String>`:
  Serialize to TOML string.

**IdentityEntry methods for converting to EtaExpression:**

Add a method to IdentityEntry:
```rust
impl IdentityEntry {
    /// Try to convert LHS to an EtaExpression.
    /// Returns None if the LHS is not of type "eta_quotient" or lacks required fields.
    pub fn lhs_as_eta(&self) -> Option<EtaExpression> {
        side_to_eta(&self.lhs)
    }

    /// Try to convert RHS to an EtaExpression.
    pub fn rhs_as_eta(&self) -> Option<EtaExpression> {
        side_to_eta(&self.rhs)
    }
}

fn side_to_eta(side: &IdentitySide) -> Option<EtaExpression> {
    if side.expr_type != "eta_quotient" {
        return None;
    }
    let level = side.level?;
    let factors_map = side.factors.as_ref()?;
    let mut factors = BTreeMap::new();
    for (k, v) in factors_map {
        let delta: i64 = k.parse().ok()?;
        factors.insert(delta, *v);
    }
    let pairs: Vec<(i64, i64)> = factors.into_iter().collect();
    Some(EtaExpression::from_factors(&pairs, level))
}
```

**Step 3: Update identity/mod.rs to include database module.**

Add to the existing module declarations (after prove):
```rust
pub mod database;
```

Add to the existing re-exports:
```rust
pub use database::{IdentityEntry, IdentityDatabase};
```

**Step 4: Update qseries/mod.rs re-exports.**

Add `IdentityEntry` and `IdentityDatabase` to the existing identity re-export line. Since Plans 07-01 through 07-03 have already run (this is wave 4), the re-export line should now include all identity types. Read the current state of mod.rs and append the database types to the existing re-export.

Imports in database.rs:
```rust
use std::collections::BTreeMap;
use serde::{Serialize, Deserialize};
use super::eta::EtaExpression;
```
  </action>
  <verify>
    `export PATH="/c/mingw64-gcc/mingw64/bin:/c/cygwin64/bin:/c/Users/Owner/.cargo/bin:$PATH" && cargo build -p qsym-core 2>&1` compiles without errors. The toml crate is successfully resolved.
  </verify>
  <done>
    IdentityEntry and IdentityDatabase structs with TOML serde support. Database supports load_from_toml, load_from_file, search_by_tag, search_by_function, search_by_pattern, and to_toml. IdentityEntry can convert to EtaExpression via lhs_as_eta/rhs_as_eta. toml 0.8.x added as dependency.
  </done>
</task>

<task type="auto">
  <name>Task 2: Seed identity database with classical identities</name>
  <files>
    data/identities/classical_identities.toml
  </files>
  <action>
Create `data/identities/` directory and seed with a TOML file containing at least 10 well-known q-series identities.

Create directory structure first: `mkdir -p data/identities`.

Write `classical_identities.toml` with these identities:

```toml
# Classical q-series identities
# Each [[identity]] block represents one verified identity.

[[identity]]
id = "euler-pentagonal"
name = "Euler's Pentagonal Number Theorem"
tags = ["euler", "pentagonal", "partition", "classical", "fundamental"]
functions = ["eta"]

[identity.lhs]
type = "eta_quotient"
level = 1
factors = { "1" = 1 }

[identity.rhs]
type = "q_series"
formula = "sum_{n=-inf}^{inf} (-1)^n * q^{n(3n-1)/2}"

[identity.proof]
method = "classical"
verified = true

[identity.citation]
author = "Euler"
year = 1750
reference = "De partitione numerorum"


[[identity]]
id = "jacobi-triple-product"
name = "Jacobi Triple Product Identity"
tags = ["jacobi", "triple-product", "classical", "fundamental"]
functions = ["eta", "jac", "theta"]

[identity.lhs]
type = "q_series"
formula = "sum_{n=-inf}^{inf} z^n * q^{n^2}"

[identity.rhs]
type = "q_series"
formula = "(q^2;q^2)_inf * (-zq;q^2)_inf * (-q/z;q^2)_inf"

[identity.proof]
method = "classical"
verified = true

[identity.citation]
author = "Jacobi"
year = 1829
reference = "Fundamenta Nova Theoriae Functionum Ellipticarum"


[[identity]]
id = "ramanujan-delta"
name = "Ramanujan's Discriminant Function"
tags = ["ramanujan", "delta", "modular-form", "weight-12"]
functions = ["eta"]

[identity.lhs]
type = "eta_quotient"
level = 1
factors = { "1" = 24 }

[identity.rhs]
type = "q_series"
formula = "q * prod_{n=1}^{inf} (1-q^n)^24 = sum tau(n) q^n"

[identity.proof]
method = "definition"
verified = true

[identity.citation]
author = "Ramanujan"
year = 1916
reference = "On certain arithmetical functions, Trans. Cambridge Phil. Soc. 22"


[[identity]]
id = "ramanujan-p5n4"
name = "Ramanujan Partition Congruence mod 5"
tags = ["ramanujan", "partition", "congruence", "mod-5"]
functions = ["eta"]

[identity.lhs]
type = "eta_quotient"
level = 5
factors = { "5" = 5 }

[identity.rhs]
type = "q_series"
formula = "5 * eta(5*tau)^5 / eta(tau)^6 implies p(5n+4) = 0 (mod 5)"

[identity.proof]
method = "valence_formula"
level = 5
verified = true

[identity.citation]
author = "Ramanujan"
year = 1919
reference = "Some properties of p(n), Proc. Cambridge Phil. Soc. 19"


[[identity]]
id = "rogers-ramanujan-1"
name = "First Rogers-Ramanujan Identity"
tags = ["rogers", "ramanujan", "rogers-ramanujan", "continued-fraction", "classical"]
functions = ["eta", "theta"]

[identity.lhs]
type = "q_series"
formula = "sum_{n=0}^{inf} q^{n^2} / (q;q)_n"

[identity.rhs]
type = "q_series"
formula = "1 / ((q;q^5)_inf * (q^4;q^5)_inf)"

[identity.proof]
method = "bijective"
verified = true

[identity.citation]
author = "Rogers"
year = 1894
reference = "Second memoir on the expansion of certain infinite products"


[[identity]]
id = "rogers-ramanujan-2"
name = "Second Rogers-Ramanujan Identity"
tags = ["rogers", "ramanujan", "rogers-ramanujan", "continued-fraction", "classical"]
functions = ["eta", "theta"]

[identity.lhs]
type = "q_series"
formula = "sum_{n=0}^{inf} q^{n(n+1)} / (q;q)_n"

[identity.rhs]
type = "q_series"
formula = "1 / ((q^2;q^5)_inf * (q^3;q^5)_inf)"

[identity.proof]
method = "bijective"
verified = true

[identity.citation]
author = "Rogers"
year = 1894
reference = "Second memoir on the expansion of certain infinite products"


[[identity]]
id = "quintuple-product"
name = "Watson's Quintuple Product Identity"
tags = ["watson", "quintuple", "product-identity", "classical"]
functions = ["eta", "theta"]

[identity.lhs]
type = "q_series"
formula = "prod_{n>=1} (1-q^n)(1-zq^n)(1-z^{-1}q^{n-1})(1-z^2q^{2n-1})(1-z^{-2}q^{2n-1})"

[identity.rhs]
type = "q_series"
formula = "sum_{n=-inf}^{inf} (z^{3n} - z^{-3n-1}) * q^{n(3n+1)/2}"

[identity.proof]
method = "classical"
verified = true

[identity.citation]
author = "Watson"
year = 1929
reference = "Proof of certain identities in combinatory analysis"


[[identity]]
id = "winquist-identity"
name = "Winquist's Identity"
tags = ["winquist", "product-identity", "partition", "mod-10"]
functions = ["eta"]

[identity.lhs]
type = "q_series"
formula = "(q;q)_inf^2 * prod of 8 Pochhammer factors in a,b"

[identity.rhs]
type = "q_series"
formula = "Double sum expressing p(10n+6) congruence"

[identity.proof]
method = "classical"
verified = true

[identity.citation]
author = "Winquist"
year = 1969
reference = "An elementary proof of p(11m+6) = 0 (mod 11)"


[[identity]]
id = "eta-dedekind-functional-eq"
name = "Dedekind Eta Functional Equation"
tags = ["dedekind", "eta", "modular-transformation", "classical", "fundamental"]
functions = ["eta"]

[identity.lhs]
type = "eta_quotient"
level = 1
factors = { "1" = 1 }

[identity.rhs]
type = "q_series"
formula = "eta(-1/tau) = sqrt(-i*tau) * eta(tau)"

[identity.proof]
method = "classical"
verified = true

[identity.citation]
author = "Dedekind"
year = 1877
reference = "Erlauterungen zu den Fragmenten XXVIII"


[[identity]]
id = "ramanujan-p7n5"
name = "Ramanujan Partition Congruence mod 7"
tags = ["ramanujan", "partition", "congruence", "mod-7"]
functions = ["eta"]

[identity.lhs]
type = "eta_quotient"
level = 7
factors = { "7" = 3 }

[identity.rhs]
type = "q_series"
formula = "7 * eta(7*tau)^3 / eta(tau)^4 + ... implies p(7n+5) = 0 (mod 7)"

[identity.proof]
method = "valence_formula"
level = 7
verified = true

[identity.citation]
author = "Ramanujan"
year = 1919
reference = "Some properties of p(n), Proc. Cambridge Phil. Soc. 19"


[[identity]]
id = "gauss-triangular"
name = "Gauss Triangular Number Theorem"
tags = ["gauss", "triangular", "theta", "classical"]
functions = ["eta", "theta"]

[identity.lhs]
type = "q_series"
formula = "sum_{n=0}^{inf} q^{n(n+1)/2}"

[identity.rhs]
type = "q_series"
formula = "(q^2;q^2)_inf / (q;q^2)_inf"

[identity.proof]
method = "jacobi-triple-product"
verified = true

[identity.citation]
author = "Gauss"
year = 1801
reference = "Disquisitiones Arithmeticae"


[[identity]]
id = "theta3-jacobi"
name = "Jacobi Theta Function theta_3"
tags = ["jacobi", "theta", "theta3", "classical"]
functions = ["theta", "jac"]

[identity.lhs]
type = "q_series"
formula = "sum_{n=-inf}^{inf} q^{n^2}"

[identity.rhs]
type = "q_series"
formula = "(-q;q^2)_inf^2 * (q^2;q^2)_inf = JAC(1,2)"

[identity.proof]
method = "jacobi-triple-product"
verified = true

[identity.citation]
author = "Jacobi"
year = 1829
reference = "Fundamenta Nova"
```

That's 12 identities covering: Euler, Jacobi, Ramanujan, Rogers, Watson, Winquist, Dedekind, and Gauss. Tags span: classical, partition, congruence, theta, eta, product-identity, modular-form. Functions span: eta, theta, jac.
  </action>
  <verify>
    Verify the TOML file parses correctly by writing a quick test or checking with `cargo test` (the database test in Task 3 will validate this).
  </verify>
  <done>
    data/identities/classical_identities.toml contains 12 well-known identities with id, name, tags, functions, LHS/RHS descriptions, proof info, and citations. Covers Euler, Jacobi, Ramanujan, Rogers-Ramanujan, Watson, Winquist, Dedekind, and Gauss.
  </done>
</task>

<task type="auto">
  <name>Task 3: Python API bindings and integration tests for database</name>
  <files>
    crates/qsym-python/src/dsl.rs
    crates/qsym-python/src/lib.rs
    crates/qsym-core/tests/qseries_identity_database_tests.rs
  </files>
  <action>
**Step 1: Create Rust integration tests for the identity database.**

```rust
//! Tests for identity database TOML loading, searching, and round-trip serialization.

use qsym_core::qseries::identity::{IdentityDatabase, IdentityEntry};

const CLASSICAL_TOML: &str = include_str!("../../../data/identities/classical_identities.toml");
```

Note: The `include_str!` path is relative to the test file at `crates/qsym-core/tests/`. Going `../../../` reaches the workspace root, then `data/identities/classical_identities.toml`. Verify this is correct.

**Test 1: Load classical identities from TOML**
```rust
#[test]
fn load_classical_identities() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).expect("Should parse TOML");
    assert!(db.len() >= 10, "Should have at least 10 identities, got {}", db.len());
}
```

**Test 2: Search by tag**
```rust
#[test]
fn search_by_tag_classical() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let results = db.search_by_tag("classical");
    assert!(results.len() >= 5, "Should find multiple classical identities");
}

#[test]
fn search_by_tag_ramanujan() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let results = db.search_by_tag("ramanujan");
    assert!(results.len() >= 2, "Should find Ramanujan identities");
}

#[test]
fn search_by_tag_nonexistent() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let results = db.search_by_tag("nonexistent-tag-xyz");
    assert!(results.is_empty());
}
```

**Test 3: Search by function**
```rust
#[test]
fn search_by_function_eta() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let results = db.search_by_function("eta");
    assert!(results.len() >= 5, "Should find multiple eta-related identities");
}

#[test]
fn search_by_function_theta() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let results = db.search_by_function("theta");
    assert!(results.len() >= 2, "Should find theta-related identities");
}
```

**Test 4: Get by ID**
```rust
#[test]
fn get_by_id() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let entry = db.get("euler-pentagonal");
    assert!(entry.is_some());
    assert_eq!(entry.unwrap().name, "Euler's Pentagonal Number Theorem");
}
```

**Test 5: Search by pattern**
```rust
#[test]
fn search_by_pattern() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let results = db.search_by_pattern("partition");
    assert!(results.len() >= 2, "Should find partition-related identities");
}
```

**Test 6: Round-trip serialization**
```rust
#[test]
fn round_trip_toml() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let toml_str = db.to_toml().expect("Should serialize to TOML");
    let db2 = IdentityDatabase::load_from_toml(&toml_str).expect("Should re-parse");
    assert_eq!(db.len(), db2.len());
    // Check a specific entry survived round-trip
    let e1 = db.get("euler-pentagonal").unwrap();
    let e2 = db2.get("euler-pentagonal").unwrap();
    assert_eq!(e1.name, e2.name);
    assert_eq!(e1.tags, e2.tags);
}
```

**Test 7: Convert IdentityEntry to EtaExpression**
```rust
#[test]
fn identity_entry_to_eta_expression() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let entry = db.get("ramanujan-delta").unwrap();
    let eta = entry.lhs_as_eta();
    assert!(eta.is_some(), "Delta function LHS should convert to EtaExpression");
    let eta = eta.unwrap();
    assert_eq!(eta.level, 1);
    assert_eq!(*eta.factors.get(&1).unwrap(), 24);
}
```

**Test 8: Non-eta entry returns None for conversion**
```rust
#[test]
fn non_eta_entry_conversion_returns_none() {
    let db = IdentityDatabase::load_from_toml(CLASSICAL_TOML).unwrap();
    let entry = db.get("jacobi-triple-product").unwrap();
    // This has type "q_series", not "eta_quotient"
    let eta = entry.lhs_as_eta();
    assert!(eta.is_none(), "q_series type should not convert to EtaExpression");
}
```

**Step 2: Add Python bindings for identity proving and database search.**

Add a new group (Group 9: Identity Proving) to dsl.rs, after the existing Group 8:

```rust
// ===========================================================================
// GROUP 9: Identity Proving and Database
// ===========================================================================
```

**Function: prove_eta_id**
```rust
/// Prove an eta-quotient identity via the valence formula.
///
/// Takes two sides as lists of (delta, r_delta) pairs and a level N.
/// Returns a dict with proof result.
///
/// ```python
/// s = QSession()
/// result = prove_eta_id(s, [(5, 6)], [(1, 6)], 5)
/// print(result["status"])  # "proved", "not_modular", "negative_order", "counterexample"
/// ```
#[pyfunction]
#[pyo3(signature = (session, lhs_factors, rhs_factors, level))]
pub fn prove_eta_id(
    session: &QSession,
    lhs_factors: Vec<(i64, i64)>,
    rhs_factors: Vec<(i64, i64)>,
    level: i64,
) -> PyResult<PyObject> {
    let _ = session; // Session not needed for proving, but keeps API consistent

    use qsym_core::qseries::identity::{EtaExpression, EtaIdentity, prove_eta_identity, ProofResult};

    let lhs = EtaExpression::from_factors(&lhs_factors, level);
    let rhs = EtaExpression::from_factors(&rhs_factors, level);
    let identity = EtaIdentity::two_sided(lhs, rhs, level);
    let result = prove_eta_identity(&identity);

    Python::with_gil(|py| {
        let dict = PyDict::new(py);
        match &result {
            ProofResult::Proved { level, cusp_orders, sturm_bound, verification_terms } => {
                dict.set_item("status", "proved")?;
                dict.set_item("level", *level)?;
                dict.set_item("sturm_bound", *sturm_bound)?;
                dict.set_item("verification_terms", *verification_terms)?;
                let cusps_list: Vec<(String, String)> = cusp_orders.iter()
                    .map(|(c, o)| (format!("{}", c), format!("{}", o)))
                    .collect();
                dict.set_item("cusp_orders", cusps_list)?;
            }
            ProofResult::NotModular { failed_conditions } => {
                dict.set_item("status", "not_modular")?;
                dict.set_item("failed_conditions", failed_conditions.clone())?;
            }
            ProofResult::NegativeOrder { cusp, order } => {
                dict.set_item("status", "negative_order")?;
                dict.set_item("cusp", format!("{}", cusp))?;
                dict.set_item("order", format!("{}", order))?;
            }
            ProofResult::CounterExample { coefficient_index, expected, actual } => {
                dict.set_item("status", "counterexample")?;
                dict.set_item("coefficient_index", *coefficient_index)?;
                dict.set_item("expected", format!("{}", expected))?;
                dict.set_item("actual", format!("{}", actual))?;
            }
        }
        Ok(dict.into())
    })
}
```

**Function: search_identities**
```rust
/// Search the identity database by tag, function, or pattern.
///
/// ```python
/// results = search_identities("classical", search_type="tag")
/// results = search_identities("eta", search_type="function")
/// results = search_identities("partition", search_type="pattern")
/// ```
#[pyfunction]
#[pyo3(signature = (query, search_type = "pattern", db_path = None))]
pub fn search_identities(
    py: Python<'_>,
    query: &str,
    search_type: &str,
    db_path: Option<&str>,
) -> PyResult<PyObject> {
    use qsym_core::qseries::identity::IdentityDatabase;

    // Load from specified path or use embedded default database
    let toml_content = if let Some(path) = db_path {
        std::fs::read_to_string(path)
            .map_err(|e| pyo3::exceptions::PyIOError::new_err(format!("Cannot read {}: {}", path, e)))?
    } else {
        // Use embedded default database
        // include_str! path is relative to THIS source file (dsl.rs)
        include_str!("../../../data/identities/classical_identities.toml").to_string()
    };

    let db = IdentityDatabase::load_from_toml(&toml_content)
        .map_err(|e| pyo3::exceptions::PyValueError::new_err(e))?;

    let results: Vec<&qsym_core::qseries::identity::IdentityEntry> = match search_type {
        "tag" => db.search_by_tag(query),
        "function" => db.search_by_function(query),
        "pattern" | _ => db.search_by_pattern(query),
    };

    let py_results: Vec<PyObject> = results.iter().map(|entry| {
        let dict = PyDict::new(py);
        dict.set_item("id", &entry.id).unwrap();
        dict.set_item("name", &entry.name).unwrap();
        dict.set_item("tags", &entry.tags).unwrap();
        dict.set_item("functions", &entry.functions).unwrap();
        if let Some(ref citation) = entry.citation {
            if let Some(ref author) = citation.author {
                dict.set_item("author", author).unwrap();
            }
            if let Some(year) = citation.year {
                dict.set_item("year", year).unwrap();
            }
        }
        dict.into()
    }).collect();

    Ok(PyList::new(py, &py_results)?.into())
}
```

**Step 3: Register new Python functions in lib.rs.**

Add to the `_qsymbolic` module function, after Group 8:
```rust
// Group 9: Identity Proving
m.add_function(wrap_pyfunction!(dsl::prove_eta_id, m)?)?;
m.add_function(wrap_pyfunction!(dsl::search_identities, m)?)?;
```
  </action>
  <verify>
    `export PATH="/c/mingw64-gcc/mingw64/bin:/c/cygwin64/bin:/c/Users/Owner/.cargo/bin:$PATH" && cargo test --lib --tests -p qsym-core --test qseries_identity_database_tests 2>&1` -- all tests pass.

    `export PATH="/c/mingw64-gcc/mingw64/bin:/c/cygwin64/bin:/c/Users/Owner/.cargo/bin:$PATH" && cargo build -p qsym-python 2>&1` -- Python bindings compile.

    `export PATH="/c/mingw64-gcc/mingw64/bin:/c/cygwin64/bin:/c/Users/Owner/.cargo/bin:$PATH" && cargo test --lib --tests -p qsym-core 2>&1` -- all existing tests still pass.
  </verify>
  <done>
    Identity database loads from TOML with 12+ classical identities. Search by tag returns correct results (e.g., "ramanujan" finds >= 2 entries). Search by function filters correctly. Round-trip serialization preserves all data. IdentityEntry converts to EtaExpression for eta_quotient types. Python bindings expose prove_eta_id and search_identities functions. Python crate compiles successfully.
  </done>
</task>

</tasks>

<verification>
1. `cargo build -p qsym-core` -- compiles with toml dependency
2. `cargo test -p qsym-core --test qseries_identity_database_tests` -- all tests pass
3. `cargo build -p qsym-python` -- Python bindings compile
4. `cargo test -p qsym-core` -- all existing tests still pass
5. Database loads 10+ identities from classical_identities.toml
6. search_by_tag("ramanujan") returns >= 2 results
7. Round-trip TOML serialization preserves identity data
</verification>

<success_criteria>
- TOML identity database loads, saves, and searches correctly
- At least 10 classical identities are seeded with tags, functions, and citations
- Search by tag, function, and pattern all work with case-insensitive matching
- IdentityEntry.lhs_as_eta() converts eta_quotient entries to EtaExpression
- Python prove_eta_id function calls the Rust proving engine and returns structured dict
- Python search_identities function searches the embedded database
- The toml crate integrates cleanly with existing serde infrastructure
</success_criteria>

<output>
After completion, create `.planning/phases/07-identity-proving/07-04-SUMMARY.md`
</output>
