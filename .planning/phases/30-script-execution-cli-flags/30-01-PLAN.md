---
phase: 30-script-execution-cli-flags
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/qsym-cli/src/token.rs
  - crates/qsym-cli/src/lexer.rs
  - crates/qsym-cli/src/ast.rs
  - crates/qsym-cli/src/parser.rs
  - crates/qsym-cli/src/eval.rs
  - crates/qsym-cli/src/script.rs
  - crates/qsym-cli/src/lib.rs
autonomous: true
requirements: [EXEC-02, EXEC-03, EXEC-05]

must_haves:
  truths:
    - "Lexer tokenizes # comments as whitespace (skips to end of line)"
    - "Lexer treats newline and carriage return as whitespace"
    - "Lexer tokenizes double-quoted string literals into Token::StringLit"
    - "Parser produces AstNode::StringLit from Token::StringLit"
    - "eval_expr returns Value::String from AstNode::StringLit"
    - "execute_source() parses and evaluates multi-statement source text, printing results"
    - "execute_file() reads a file and passes its contents to execute_source()"
    - "Multi-line expressions with unclosed parens parse correctly across newlines"
  artifacts:
    - path: "crates/qsym-cli/src/token.rs"
      provides: "Token::StringLit(String) variant"
      contains: "StringLit"
    - path: "crates/qsym-cli/src/lexer.rs"
      provides: "Tokenization of # comments, newlines, and string literals"
      contains: "StringLit"
    - path: "crates/qsym-cli/src/ast.rs"
      provides: "AstNode::StringLit(String) variant"
      contains: "StringLit"
    - path: "crates/qsym-cli/src/parser.rs"
      provides: "StringLit handling in Pratt prefix and token_name()"
      contains: "StringLit"
    - path: "crates/qsym-cli/src/eval.rs"
      provides: "Value::String variant and AstNode::StringLit evaluation"
      contains: "Value::String"
    - path: "crates/qsym-cli/src/script.rs"
      provides: "execute_source(), execute_file(), ScriptResult enum, exit code constants"
      exports: ["execute_source", "execute_file", "ScriptResult"]
    - path: "crates/qsym-cli/src/lib.rs"
      provides: "pub mod script declaration"
      contains: "pub mod script"
  key_links:
    - from: "crates/qsym-cli/src/script.rs"
      to: "crates/qsym-cli/src/parser.rs"
      via: "parser::parse() call"
      pattern: "crate::parser::parse"
    - from: "crates/qsym-cli/src/script.rs"
      to: "crates/qsym-cli/src/eval.rs"
      via: "eval::eval_stmt_safe() call"
      pattern: "eval::eval_stmt_safe"
    - from: "crates/qsym-cli/src/parser.rs"
      to: "crates/qsym-cli/src/lexer.rs"
      via: "tokenize() call (lexer handles # and newlines)"
      pattern: "tokenize"
---

<objective>
Extend the lexer/parser/AST/eval pipeline to support script-mode features (comments, newlines, string literals) and create the shared script execution engine.

Purpose: All non-interactive modes (script files, -c expressions, piped stdin, read()) need a common execution engine that can parse and evaluate multi-statement source text with # comments. The lexer must treat newlines as whitespace and handle # comments so multi-line scripts parse correctly. String literals are needed for the read("file.qk") function syntax.

Output: Extended lexer/parser/AST/eval with comment/newline/string support, plus a new script.rs module providing execute_source() and execute_file().
</objective>

<execution_context>
@C:/Users/Owner/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Owner/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/30-script-execution-cli-flags/30-RESEARCH.md
@crates/qsym-cli/src/token.rs
@crates/qsym-cli/src/lexer.rs
@crates/qsym-cli/src/ast.rs
@crates/qsym-cli/src/parser.rs
@crates/qsym-cli/src/eval.rs
@crates/qsym-cli/src/lib.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend lexer/token/AST/parser with comments, newlines, and string literals</name>
  <files>
    crates/qsym-cli/src/token.rs
    crates/qsym-cli/src/lexer.rs
    crates/qsym-cli/src/ast.rs
    crates/qsym-cli/src/parser.rs
  </files>
  <action>
**token.rs:** Add a new variant `StringLit(String)` to the `Token` enum, placed after `Ident(String)`. Doc comment: `/// Double-quoted string literal.`

**lexer.rs:** Make three changes to the `tokenize()` function:

1. **Newline/CR as whitespace:** Change line 26 from:
   `if b == b' ' || b == b'\t' {`
   to:
   `if b == b' ' || b == b'\t' || b == b'\n' || b == b'\r' {`
   Update the comment above it to: `// Skip whitespace (space, tab, newline, carriage return)`

2. **# comment handling:** After the whitespace skip block (after `continue;` on line 29) and BEFORE the single-character tokens match, add:
   ```rust
   // Skip # line comments
   if b == b'#' {
       while pos < bytes.len() && bytes[pos] != b'\n' {
           pos += 1;
       }
       continue;
   }
   ```

3. **String literal tokenization:** After the `#` comment block and BEFORE the single-character tokens match, add:
   ```rust
   // String literals (double-quoted)
   if b == b'"' {
       let start = pos;
       pos += 1; // skip opening quote
       let mut value = String::new();
       while pos < bytes.len() && bytes[pos] != b'"' {
           if bytes[pos] == b'\\' && pos + 1 < bytes.len() {
               match bytes[pos + 1] {
                   b'\\' => { value.push('\\'); pos += 2; }
                   b'"' => { value.push('"'); pos += 2; }
                   b'n' => { value.push('\n'); pos += 2; }
                   b't' => { value.push('\t'); pos += 2; }
                   _ => { value.push(bytes[pos] as char); pos += 1; }
               }
           } else {
               value.push(bytes[pos] as char);
               pos += 1;
           }
       }
       if pos >= bytes.len() {
           return Err(ParseError::new(
               "unterminated string literal".to_string(),
               Span::new(start, pos),
           ));
       }
       pos += 1; // skip closing quote
       tokens.push(SpannedToken {
           token: Token::StringLit(value),
           span: Span::new(start, pos),
       });
       continue;
   }
   ```

Add unit tests to the lexer `tests` module:
- `test_comment_skipping`: `tokens("1 + 2 # this is ignored")` produces `[Integer(1), Plus, Integer(2), Eof]`
- `test_comment_full_line`: `tokens("# comment\n1")` produces `[Integer(1), Eof]`
- `test_newline_as_whitespace`: `tokens("1\n+\n2")` produces `[Integer(1), Plus, Integer(2), Eof]`
- `test_string_literal`: `tokens(r#""hello""#)` produces `[StringLit("hello".to_string()), Eof]`
- `test_string_escape_quote`: `tokens(r#""say \"hi\"""#)` produces `[StringLit("say \"hi\"".to_string()), Eof]`
- `test_string_unterminated`: `tokenize(r#""hello"#).unwrap_err()` asserts error message contains "unterminated"
- `test_comment_after_string`: Verify `"file.qk" # comment` tokenizes correctly (string first, then comment skipped)
- `test_multiline_expression`: `tokens("aqprod(\n  q,q,\n  infinity,20\n)")` produces the same tokens as the single-line form

**ast.rs:** Add a new variant `StringLit(String)` to the `AstNode` enum, placed after `Infinity`. Doc comment: `/// String literal value.`

**parser.rs:** Two changes:

1. In `expr_bp()` prefix section, add a new arm after the `Token::Percent` arm:
   ```rust
   Token::StringLit(ref s) => {
       let s = s.clone();
       self.advance();
       AstNode::StringLit(s)
   }
   ```

2. In `token_name()`, add before the `Token::Eof` arm:
   ```rust
   Token::StringLit(s) => format!("string \"{}\"", s),
   ```

Add a parser test:
- `test_string_literal_parse`: `parse_expr(r#""file.qk""#)` equals `AstNode::StringLit("file.qk".to_string())`
- `test_string_in_function_call`: `parse_expr(r#"read("file.qk")"#)` equals `AstNode::FuncCall { name: "read".to_string(), args: vec![AstNode::StringLit("file.qk".to_string())] }`
  </action>
  <verify>
Run: `export PATH="/c/mingw64-gcc/mingw64/bin:/c/cygwin64/bin:/c/Users/Owner/.cargo/bin:$PATH" && cd /c/cygwin64/home/Owner/Kangaroo && cargo test -p qsym-cli --lib 2>&1 | tail -5`

All existing tests pass. New lexer tests pass. New parser tests pass. No compiler warnings about non-exhaustive patterns.
  </verify>
  <done>
Lexer handles # comments (skips to EOL), \n/\r as whitespace, and double-quoted string literals with escape sequences. Parser produces AstNode::StringLit. token_name() covers StringLit. All 294+ existing CLI tests still pass, plus new tests for comments, newlines, and strings.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create script.rs execution engine and add Value::String to eval</name>
  <files>
    crates/qsym-cli/src/eval.rs
    crates/qsym-cli/src/script.rs
    crates/qsym-cli/src/lib.rs
  </files>
  <action>
**eval.rs:** Three changes:

1. Add `String(String)` variant to the `Value` enum, placed after `Bool(bool)`. Doc comment: `/// String value (for filenames, etc.).`

2. Add `"string"` arm to `Value::type_name()`:
   ```rust
   Value::String(_) => "string",
   ```

3. In `eval_expr()`, add handling for `AstNode::StringLit` after the `AstNode::Infinity` arm:
   ```rust
   AstNode::StringLit(s) => Ok(Value::String(s.clone())),
   ```

4. In `format_value()` in `format.rs`, add handling for `Value::String`:
   ```rust
   Value::String(s) => s.clone(),
   ```
   Also in `format_latex()`, add:
   ```rust
   Value::String(s) => format!("\\text{{{}}}", s),
   ```

**script.rs:** Create this new file with:

```rust
//! Script execution engine for non-interactive modes.
//!
//! Provides [`execute_source()`] and [`execute_file()`] for running
//! q-Kangaroo code from script files, `-c` expressions, and piped stdin.

use crate::environment::Environment;
use crate::eval::{self, Value};
use crate::format::format_value;

// ---------------------------------------------------------------------------
// Exit code constants (sysexits-compatible)
// ---------------------------------------------------------------------------

/// Normal termination.
pub const EXIT_SUCCESS: u8 = 0;
/// Evaluation error (runtime error).
pub const EXIT_EVAL_ERROR: u8 = 1;
/// Bad CLI usage (unknown flag, missing argument).
pub const EXIT_USAGE: u8 = 2;
/// Parse error in input (syntax error).
pub const EXIT_PARSE_ERROR: u8 = 65;
/// Script file not found or unreadable.
pub const EXIT_FILE_NOT_FOUND: u8 = 66;
/// Caught panic from qsym-core.
pub const EXIT_PANIC: u8 = 70;

// ---------------------------------------------------------------------------
// ScriptResult
// ---------------------------------------------------------------------------

/// Result of executing a script or expression.
pub enum ScriptResult {
    /// All statements executed successfully.
    Success,
    /// A parse error occurred.
    ParseError(String),
    /// An eval error occurred.
    EvalError(String),
    /// A caught panic.
    Panic(String),
}

impl ScriptResult {
    /// Convert to an exit code.
    pub fn exit_code(&self) -> u8 {
        match self {
            ScriptResult::Success => EXIT_SUCCESS,
            ScriptResult::ParseError(_) => EXIT_PARSE_ERROR,
            ScriptResult::EvalError(_) => EXIT_EVAL_ERROR,
            ScriptResult::Panic(_) => EXIT_PANIC,
        }
    }

    /// Get the error message, if any.
    pub fn error_message(&self) -> Option<&str> {
        match self {
            ScriptResult::Success => None,
            ScriptResult::ParseError(msg) => Some(msg),
            ScriptResult::EvalError(msg) => Some(msg),
            ScriptResult::Panic(msg) => Some(msg),
        }
    }
}

// ---------------------------------------------------------------------------
// execute_source
// ---------------------------------------------------------------------------

/// Execute a source string containing one or more statements.
///
/// Parses the entire source (comments and newlines handled by the lexer)
/// and evaluates each statement. Results of non-suppressed statements
/// (those with `;` or implicit terminator) are printed to stdout.
///
/// If `verbose` is true, per-statement timing is printed to stderr.
///
/// Stops on the first error (fail-fast).
pub fn execute_source(
    source: &str,
    env: &mut Environment,
    verbose: bool,
) -> ScriptResult {
    // The lexer handles # comments and \n as whitespace, and the parser
    // splits statements on ; and : terminators. So we can pass the entire
    // source to parse() directly.
    let stmts = match crate::parser::parse(source) {
        Ok(stmts) => stmts,
        Err(e) => return ScriptResult::ParseError(e.render(source)),
    };

    for stmt in &stmts {
        let start = if verbose {
            Some(std::time::Instant::now())
        } else {
            None
        };

        match eval::eval_stmt_safe(stmt, env) {
            Ok(Some(val)) => {
                println!("{}", format_value(&val));
                if let Some(t) = start {
                    eprintln!("  [{:.3}s]", t.elapsed().as_secs_f64());
                }
            }
            Ok(None) => {
                if let Some(t) = start {
                    eprintln!("  [{:.3}s]", t.elapsed().as_secs_f64());
                }
            }
            Err(e) => {
                let msg = format!("{}", e);
                return if matches!(e, eval::EvalError::Panic(_)) {
                    ScriptResult::Panic(msg)
                } else {
                    ScriptResult::EvalError(msg)
                };
            }
        }
    }

    ScriptResult::Success
}

// ---------------------------------------------------------------------------
// execute_file
// ---------------------------------------------------------------------------

/// Execute a script file by path.
///
/// Reads the entire file into memory and passes it to [`execute_source()`].
/// Returns `ScriptResult::EvalError` if the file cannot be read.
pub fn execute_file(
    path: &str,
    env: &mut Environment,
    verbose: bool,
) -> ScriptResult {
    match std::fs::read_to_string(path) {
        Ok(source) => execute_source(&source, env, verbose),
        Err(e) => ScriptResult::EvalError(format!("cannot read '{}': {}", path, e)),
    }
}
```

**lib.rs:** Add `pub mod script;` to the module list (alphabetical order, after `pub mod repl;`).

Add unit tests in script.rs:
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_execute_source_simple() {
        let mut env = Environment::new();
        let result = execute_source("1 + 1", &mut env, false);
        assert!(matches!(result, ScriptResult::Success));
    }

    #[test]
    fn test_execute_source_with_comments() {
        let mut env = Environment::new();
        let source = "# This is a comment\n1 + 1";
        let result = execute_source(source, &mut env, false);
        assert!(matches!(result, ScriptResult::Success));
    }

    #[test]
    fn test_execute_source_multiline() {
        let mut env = Environment::new();
        let source = "aqprod(\n  q, q,\n  infinity, 20\n)";
        let result = execute_source(source, &mut env, false);
        assert!(matches!(result, ScriptResult::Success));
    }

    #[test]
    fn test_execute_source_multi_statement() {
        let mut env = Environment::new();
        let source = "f := etaq(1,1,20):\ng := etaq(2,1,20):\nf * g";
        let result = execute_source(source, &mut env, false);
        assert!(matches!(result, ScriptResult::Success));
    }

    #[test]
    fn test_execute_source_parse_error() {
        let mut env = Environment::new();
        let result = execute_source("1 + + 2", &mut env, false);
        assert!(matches!(result, ScriptResult::ParseError(_)));
    }

    #[test]
    fn test_execute_source_eval_error() {
        let mut env = Environment::new();
        let result = execute_source("undefined_var", &mut env, false);
        assert!(matches!(result, ScriptResult::EvalError(_)));
    }

    #[test]
    fn test_execute_file_not_found() {
        let mut env = Environment::new();
        let result = execute_file("/nonexistent/path/script.qk", &mut env, false);
        assert!(matches!(result, ScriptResult::EvalError(_)));
        if let ScriptResult::EvalError(msg) = result {
            assert!(msg.contains("cannot read"));
        }
    }

    #[test]
    fn test_exit_codes() {
        assert_eq!(ScriptResult::Success.exit_code(), 0);
        assert_eq!(ScriptResult::ParseError("x".into()).exit_code(), 65);
        assert_eq!(ScriptResult::EvalError("x".into()).exit_code(), 1);
        assert_eq!(ScriptResult::Panic("x".into()).exit_code(), 70);
    }

    #[test]
    fn test_execute_source_assignment_persists() {
        let mut env = Environment::new();
        let result = execute_source("x := 42:", &mut env, false);
        assert!(matches!(result, ScriptResult::Success));
        assert!(env.get_var("x").is_some());
    }

    #[test]
    fn test_execute_source_empty() {
        let mut env = Environment::new();
        let result = execute_source("", &mut env, false);
        assert!(matches!(result, ScriptResult::Success));
    }

    #[test]
    fn test_execute_source_only_comments() {
        let mut env = Environment::new();
        let result = execute_source("# just a comment\n# another", &mut env, false);
        assert!(matches!(result, ScriptResult::Success));
    }
}
```
  </action>
  <verify>
Run: `export PATH="/c/mingw64-gcc/mingw64/bin:/c/cygwin64/bin:/c/Users/Owner/.cargo/bin:$PATH" && cd /c/cygwin64/home/Owner/Kangaroo && cargo test -p qsym-cli --lib 2>&1 | tail -5`

All tests pass including new script.rs tests. `cargo check -p qsym-cli` shows no warnings about non-exhaustive match on Value enum.
  </verify>
  <done>
Value::String variant exists in eval.rs. format_value() and format_latex() handle Value::String. script.rs provides execute_source() and execute_file() with ScriptResult enum and exit code constants. The script engine correctly parses multi-statement source with comments and newlines via the lexer, evaluates with fail-fast on errors, and prints results. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `cargo test -p qsym-cli --lib` -- all existing 294+ tests pass, plus new lexer/parser/script tests
2. `cargo check -p qsym-cli` -- no warnings about non-exhaustive patterns on Token, AstNode, or Value
3. Lexer correctly handles: `"1 + 2 # comment"`, `"a\nb"`, `"\"hello\""`, mixed multiline with comments
4. Script engine correctly handles: empty source, comments-only, multi-statement, parse errors, eval errors
</verification>

<success_criteria>
- Token::StringLit, AstNode::StringLit, Value::String variants exist
- Lexer skips # comments, treats \n/\r as whitespace, tokenizes "string" literals
- Parser produces StringLit AST nodes from StringLit tokens
- script.rs exports execute_source(), execute_file(), ScriptResult, exit code constants
- All tests pass (existing + new)
</success_criteria>

<output>
After completion, create `.planning/phases/30-script-execution-cli-flags/30-01-SUMMARY.md`
</output>
